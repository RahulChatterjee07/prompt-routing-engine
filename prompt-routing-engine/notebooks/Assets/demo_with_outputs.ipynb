{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00e7b1fd",
   "metadata": {},
   "source": [
    "# üß† Prompt Routing Engine - Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6aecf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded document image for: Correspondence"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "import os\n",
    "\n",
    "# Set your document type: 'form', 'report', 'assessment', 'correspondence'\n",
    "doc_type = \"correspondence\"\n",
    "\n",
    "# Load image\n",
    "img_path = f\"../notebooks/assets/{doc_type}_output_view_full.png\"\n",
    "display(Image(img_path))\n",
    "\n",
    "print(f\"Loaded document image for: {doc_type.capitalize()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409aebfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Prompt Template:\n",
      "--------------------------------------------------\n",
      "You are an expert document classifier. Your task is to analyze a 2-page document..."
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "# Load YAML prompt\n",
    "prompt_path = f\"../prompts/{doc_type}_prompt.yaml\"\n",
    "with open(prompt_path) as f:\n",
    "    prompt_yaml = yaml.safe_load(f)\n",
    "\n",
    "prompt = prompt_yaml[\"prompt\"]\n",
    "print(\"Loaded Prompt Template:\")\n",
    "print(\"=\"*50)\n",
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94505b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Document Length (line count): 8\n",
      "üö¶ Should call Bedrock: True\n",
      "‚úÖ Proceeding with Bedrock call..."
     ]
    }
   ],
   "source": [
    "from routing_engine.rules import extract_text_and_layout\n",
    "import json\n",
    "\n",
    "# Load the parsed Textract-like layout data\n",
    "json_path = f\"../data/textract_outputs/{doc_type}.json\"\n",
    "with open(json_path) as f:\n",
    "    textract_data = json.load(f)\n",
    "\n",
    "# Extract text lines from the layout\n",
    "text_lines, _ = extract_text_and_layout(textract_data)\n",
    "doc_length = len(text_lines)\n",
    "\n",
    "print(f\"üìù Document Length (line count): {doc_length}\")\n",
    "\n",
    "# Apply logic for Bedrock call:\n",
    "# - Call Bedrock if correspondence and length < 10\n",
    "# - OR if report and length >= 10\n",
    "should_call_bedrock = False\n",
    "if doc_type == \"correspondence\" and doc_length < 10:\n",
    "    should_call_bedrock = True\n",
    "elif doc_type == \"report\" and doc_length >= 10:\n",
    "    should_call_bedrock = True\n",
    "\n",
    "print(f\"üö¶ Should call Bedrock: {should_call_bedrock}\")\n",
    "\n",
    "# Optional: Only proceed with the call if condition is met\n",
    "if should_call_bedrock:\n",
    "    print(\"‚úÖ Proceeding with Bedrock call...\")\n",
    "    # (the Sonnet call cell follows this)\n",
    "else:\n",
    "    print(\"‚ùå Skipping Bedrock call due to document length criteria.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ae9bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated call to AWS Bedrock Claude Sonnet (pseudocode placeholder)\n",
    "# In real setup, you would use boto3 client with bedrock-runtime and pass modelId\n",
    "\n",
    "def call_bedrock_claude(prompt, image_bytes=None):\n",
    "    # Pseudocode placeholder for Bedrock call\n",
    "    print(\"Calling AWS Bedrock Claude Sonnet...\")\n",
    "    print(\"Prompt sent:\")\n",
    "    print(prompt)\n",
    "    # Here, you would encode image and send along with prompt\n",
    "    # Return mock output for now\n",
    "    return {\"completion\": \"Category: [\\\"Correspondence\\\", \\\"20-03-2024\\\"]\"}\n",
    "\n",
    "# Simulate image bytes if needed\n",
    "image_bytes = open(img_path, \"rb\").read()\n",
    "\n",
    "response = call_bedrock_claude(prompt, image_bytes=image_bytes)\n",
    "print(\"\\nModel Output:\")\n",
    "print(response[\"completion\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7912e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñºÔ∏è Original image size: 1200x900\n",
      "‚úÖ Image is within size limits."
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# Resize image if it exceeds 8000x8000 pixels\n",
    "MAX_DIM = 8000\n",
    "\n",
    "with open(img_path, \"rb\") as img_file:\n",
    "    image = Image.open(img_file)\n",
    "    width, height = image.size\n",
    "    print(f\"üñºÔ∏è Original image size: {width}x{height}\")\n",
    "\n",
    "    if width > MAX_DIM or height > MAX_DIM:\n",
    "        resize_ratio = min(MAX_DIM / width, MAX_DIM / height)\n",
    "        new_size = (int(width * resize_ratio), int(height * resize_ratio))\n",
    "        image = image.resize(new_size, Image.ANTIALIAS)\n",
    "        print(f\"‚ö†Ô∏è Image resized to: {new_size[0]}x{new_size[1]}\")\n",
    "    else:\n",
    "        print(\"‚úÖ Image is within size limits.\")\n",
    "\n",
    "    # Convert image to base64\n",
    "    buffer = io.BytesIO()\n",
    "    image.save(buffer, format=\"JPEG\")\n",
    "    img_b64 = base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "images = [img_b64]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628797c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"anthropic_version\": \"bedrock-2023-05-31\",\n",
      "  \"max_tokens\": 1500,\n",
      "  ..."
     ]
    }
   ],
   "source": [
    "import json\n",
    "import base64\n",
    "\n",
    "# Simulated system prompt and content prompt\n",
    "system_prompt = (\n",
    "    \"You are a professional document analyst specializing in extracting meaningful insights \"\n",
    "    \"from images and text. Your responses should be concise, structured, and highly accurate.\"\n",
    ")\n",
    "\n",
    "# Simulated image base64 encoding\n",
    "with open(img_path, \"rb\") as img_file:\n",
    "    img_b64 = base64.b64encode(img_file.read()).decode(\"utf-8\")\n",
    "\n",
    "images = [img_b64]  # list of images in base64\n",
    "\n",
    "# Claude Sonnet prompt content\n",
    "content_prompt = prompt  # loaded in previous cell\n",
    "\n",
    "# Construct messages for Claude\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"image\",\n",
    "                \"source\": {\n",
    "                    \"type\": \"base64\",\n",
    "                    \"media_type\": \"image/jpeg\",\n",
    "                    \"data\": img,\n",
    "                },\n",
    "            }\n",
    "            for img in images\n",
    "        ] + [{\"type\": \"text\", \"text\": content_prompt}],\n",
    "    }\n",
    "]\n",
    "\n",
    "# Final body to send to AWS Bedrock Sonnet model\n",
    "body = json.dumps(\n",
    "    {\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 1500,\n",
    "        \"system\": system_prompt,\n",
    "        \"top_p\": 0.7,\n",
    "        \"temperature\": 0.7,\n",
    "        \"messages\": messages,\n",
    "        \"stop_sequences\": [\"### END\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Prepared payload for Bedrock Claude Sonnet:\")\n",
    "print(json.dumps(json.loads(body), indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27c4a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  'category': 'Correspondence',\n",
      "  'date': '20-03-2024',\n",
      "  'is_other': 0\n",
      "}"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "def post_process_model_output(output_str):\n",
    "    \"\"\"\n",
    "    Extracts category and optional date from model output string.\n",
    "    Returns:\n",
    "        - category: str\n",
    "        - extracted_date: str or None\n",
    "        - is_other: int (0 if classified as a known tag, 1 if 'Other')\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract list from output string\n",
    "        match = re.search(r'Category:\\s*\\[(.*?)\\]', output_str)\n",
    "        if match:\n",
    "            raw = match.group(1).replace('\"', '').replace(\"'\", \"\")\n",
    "            parts = [part.strip() for part in raw.split(\",\")]\n",
    "\n",
    "            category = parts[0] if parts else \"Other\"\n",
    "            is_other = 1 if category.lower() == \"other\" else 0\n",
    "\n",
    "            # Try to extract a date\n",
    "            extracted_date = None\n",
    "            if len(parts) > 1:\n",
    "                try:\n",
    "                    extracted_date = datetime.strptime(parts[1], \"%d-%m-%Y\").strftime(\"%d-%m-%Y\")\n",
    "                except Exception:\n",
    "                    extracted_date = None\n",
    "\n",
    "            return {\n",
    "                \"category\": category,\n",
    "                \"date\": extracted_date,\n",
    "                \"is_other\": is_other\n",
    "            }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error during post-processing:\", e)\n",
    "\n",
    "    return {\"category\": \"Other\", \"date\": None, \"is_other\": 1}\n",
    "\n",
    "# Example usage:\n",
    "output_str = response[\"completion\"]\n",
    "result = post_process_model_output(output_str)\n",
    "print(\"\\nPost-Processed Result:\")\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
